import streamlit as st
import pandas as pd
import glob
import os
import re
import base64
from PIL import Image
import io
import time

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(page_title="DENE Store", layout="wide")

# --- –û–±–ª–æ–∂–∫–∞ –∏ —Ö–µ–¥–µ—Ä –∫–∞–∫ –±—ã–ª–æ ---
st.image("data/images/banner.jpg", use_container_width=True)
st.markdown("<h1 style='text-align:center; white-space: nowrap;'>DENE Store. –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å!</h1>", unsafe_allow_html=True)

# --- –ö–Ω–æ–ø–∫–∞ –∫–æ—Ä–∑–∏–Ω—ã –≤–≤–µ—Ä—Ö—É ---
col1, col2, col3 = st.columns([1, 3, 1])
with col3:
    cart_count = len(st.session_state.cart) if 'cart' in st.session_state else 0
    cart_text = f"üõí –ö–æ—Ä–∑–∏–Ω–∞ ({cart_count})" if cart_count > 0 else "üõí –ö–æ—Ä–∑–∏–Ω–∞"
    if st.button(cart_text, use_container_width=True):
        st.switch_page("pages/3_–ö–æ—Ä–∑–∏–Ω–∞.py")

# --- –ü—É—Ç–∏ –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
CATALOG_PATH = "data/catalog.xlsx"
IMAGES_PATH = "data/images"

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ---
def optimize_image_for_telegram(image_path, target_size=(300, 300)):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è Telegram"""
    try:
        with Image.open(image_path) as img:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if img.mode in ('RGBA', 'P'):
                img = img.convert('RGB')
            
            # –†–µ—Å–∞–π–∑–∏–º —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
            img.thumbnail(target_size, Image.Resampling.LANCZOS)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±—É—Ñ–µ—Ä —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=85, optimize=True)
            buffer.seek(0)
            
            return base64.b64encode(buffer.read()).decode("utf-8")
            
    except Exception as e:
        # Fallback –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        try:
            with open(image_path, "rb") as img_file:
                return base64.b64encode(img_file.read()).decode("utf-8")
        except Exception:
            fallback = os.path.join(IMAGES_PATH, "no_image.jpg")
            with open(fallback, "rb") as img_file:
                return base64.b64encode(img_file.read()).decode("utf-8")

def get_image_path(image_names):
    """–ò—â–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∏–º–µ–Ω–∏ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ image (–±–µ—Ä–µ—Ç –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–∞)"""
    if (image_names is pd.NA or 
        pd.isna(image_names) or 
        not image_names or 
        str(image_names).strip() == ""):
        return os.path.join(IMAGES_PATH, "no_image.jpg")
    
    image_names_list = str(image_names).strip().split()
    if not image_names_list:
        return os.path.join(IMAGES_PATH, "no_image.jpg")
    
    first_image_name = image_names_list[0]
    
    for ext in ['.jpg', '.jpeg', '.png', '.webp']:
        pattern = os.path.join(IMAGES_PATH, "**", f"{first_image_name}{ext}")
        image_files = glob.glob(pattern, recursive=True)
        if image_files:
            return image_files[0]
        
        pattern_start = os.path.join(IMAGES_PATH, "**", f"{first_image_name}*{ext}")
        image_files = glob.glob(pattern_start, recursive=True)
        if image_files:
            return image_files[0]
    
    return os.path.join(IMAGES_PATH, "no_image.jpg")

# --- –¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ US ‚Üî EU ---
size_conversion = {
    "1": "34", "2": "35", "3": "36", "4": "37", "5": "38",
    "6": "39", "7": "40", "8": "41", "9": "42", "10": "43",
    "11": "44", "12": "45", "13": "46",
    # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä–æ–±–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    "7.0": "40", "7.5": "40.5", "8.0": "41", "8.5": "42", 
    "9.0": "42.5", "9.5": "43", "10.0": "43.5", "10.5": "44",
    "11.0": "44.5", "11.5": "45", "12.0": "45.5", "12.5": "46"
}

# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è EU —Ä–∞–∑–º–µ—Ä–æ–≤ ---
def get_eu_sizes(us_sizes_str):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç US —Ä–∞–∑–º–µ—Ä—ã –≤ EU —Ä–∞–∑–º–µ—Ä—ã"""
    if not us_sizes_str or us_sizes_str == "":
        return ""
    
    us_sizes = [size.strip() for size in us_sizes_str.split(",")]
    eu_sizes = []
    
    for us_size in us_sizes:
        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ —Ç–∞–±–ª–∏—Ü–µ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
        eu_size = size_conversion.get(us_size, "")
        if not eu_size:
            # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à–∏–π —Ü–µ–ª—ã–π —Ä–∞–∑–º–µ—Ä
            base_size = us_size.split('.')[0]  # –ë–µ—Ä–µ–º —Ü–µ–ª—É—é —á–∞—Å—Ç—å
            eu_size = size_conversion.get(base_size, us_size)  # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º US —Ä–∞–∑–º–µ—Ä
        eu_sizes.append(eu_size)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã EU —Ä–∞–∑–º–µ—Ä–æ–≤
    unique_eu_sizes = []
    for size in eu_sizes:
        if size not in unique_eu_sizes:
            unique_eu_sizes.append(size)
    
    return ", ".join(unique_eu_sizes)

# --- –§—É–Ω–∫—Ü–∏—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ ---
def sort_sizes(size_list):
    """–°–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ"""
    numeric_sizes = []
    string_sizes = []
    
    for size in size_list:
        clean_size = str(size).strip()
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        try:
            # –î–ª—è –¥—Ä–æ–±–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
            if '.' in clean_size:
                base_num = float(clean_size)
            else:
                base_num = float(clean_size)
            numeric_sizes.append((base_num, clean_size))
        except:
            string_sizes.append(clean_size)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∏—Å–ª–æ–≤–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é
    numeric_sizes.sort(key=lambda x: x[0])
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    result = [size[1] for size in numeric_sizes] + sorted(string_sizes)
    return result

# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –≤ —Ñ–∏–ª—å—Ç—Ä–µ ---
def get_available_sizes_for_filter(df):
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ —Å —É—á–µ—Ç–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 5-11 US"""
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã –≤ –Ω–∞–ª–∏—á–∏–∏
    in_stock_df = df[df.get('in stock', 'yes').str.lower() == 'yes']
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    all_sizes = in_stock_df["size US"].dropna().unique().tolist()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É 5-11 US (–≤–∫–ª—é—á–∞—è –¥—Ä–æ–±–Ω—ã–µ)
    filtered_sizes = []
    for size in all_sizes:
        clean_size = str(size).strip()
        if not clean_size or clean_size == "nan":
            continue
            
        try:
            # –î–ª—è –¥—Ä–æ–±–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
            if '.' in clean_size:
                base_num = float(clean_size)
            else:
                base_num = float(clean_size)
            
            # –í–ö–õ–Æ–ß–ê–ï–ú —Ä–∞–∑–º–µ—Ä 11 (5-11 –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
            if 5 <= base_num <= 11:
                filtered_sizes.append(clean_size)
        except:
            # –ï—Å–ª–∏ –Ω–µ —á–∏—Å–ª–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    unique_sizes = list(dict.fromkeys(filtered_sizes))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
    return sort_sizes(unique_sizes)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
@st.cache_data(ttl=60)  # –û–±–Ω–æ–≤–ª—è—Ç—å –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
def load_data():
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –≤—Ä–µ–º–µ–Ω–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
        file_mtime = os.path.getmtime(CATALOG_PATH)
        st.sidebar.write(f"–§–∞–π–ª –æ–±–Ω–æ–≤–ª–µ–Ω: {time.ctime(file_mtime)}")
        
        # –ß–∏—Ç–∞–µ–º –≤—Å–µ –ª–∏—Å—Ç—ã Excel —Ñ–∞–π–ª–∞
        all_sheets = pd.read_excel(CATALOG_PATH, sheet_name=None)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ª–∏—Å—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
        processed_dfs = []
        
        for sheet_name, sheet_data in all_sheets.items():
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
            sheet_data = sheet_data.fillna("")
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—Ä–µ–Ω–¥–∞ –∏ –º–æ–¥–µ–ª–∏
            sheet_data['brand'] = sheet_data['brand'].replace('', pd.NA).ffill()
            sheet_data['model'] = sheet_data['model'].replace('', pd.NA).ffill()
            sheet_data['gender'] = sheet_data['gender'].replace('', pd.NA).ffill()
            
            # –î–ª—è —Ü–≤–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ, –Ω–æ –Ω–µ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            sheet_data['color'] = sheet_data['color'].replace('', pd.NA).ffill()
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å - –Ω–µ –∑–∞–ø–æ–ª–Ω—è–µ–º!
            sheet_data['image'] = sheet_data['image'].replace('', pd.NA)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –≤ —Å—Ç—Ä–æ–∫–∏ –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            sheet_data['size US'] = sheet_data['size US'].astype(str).str.strip()
            
            # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (—É–±–∏—Ä–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª—ã –≤ —Å–∫–æ–±–∫–∞—Ö)
            sheet_data["model_clean"] = sheet_data["model"].apply(
                lambda x: re.sub(r'\([^)]*\)', '', str(x)).strip() if pd.notna(x) else ""
            )
            
            processed_dfs.append(sheet_data)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ª–∏—Å—Ç—ã
        df = pd.concat(processed_dfs, ignore_index=True)
        
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –º–æ–¥–µ–ª–∏ –∏–ª–∏ –±—Ä–µ–Ω–¥–∞
        df = df[(df['brand'] != '') & (df['model_clean'] != '')]
        
        return df
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return pd.DataFrame()

# --- –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ---
df = load_data()

# --- –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê ---
st.sidebar.write("–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê:")
st.sidebar.write("–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤:", len(df))
st.sidebar.write("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –±—Ä–µ–Ω–¥—ã:", df["brand"].nunique())
st.sidebar.write("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏:", df["model_clean"].nunique())

# --- –£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã ---
st.divider()
st.markdown("### –§–∏–ª—å—Ç—Ä –∫–∞—Ç–∞–ª–æ–≥–∞")

col1, col2, col3, col4, col5 = st.columns(5)

# –ë—Ä–µ–Ω–¥
brand_filter = col1.selectbox("–ë—Ä–µ–Ω–¥", ["–í—Å–µ"] + sorted(df["brand"].unique().tolist()))

# –ú–æ–¥–µ–ª—å (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –±—Ä–µ–Ω–¥–∞)
if brand_filter != "–í—Å–µ":
    brand_models = sorted(df[df["brand"] == brand_filter]["model_clean"].unique().tolist())
else:
    brand_models = sorted(df["model_clean"].unique().tolist())
model_filter = col2.selectbox("–ú–æ–¥–µ–ª—å", ["–í—Å–µ"] + brand_models)

# –†–∞–∑–º–µ—Ä—ã - US 5-11 (–í–ö–õ–Æ–ß–ê–Ø 11) –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
available_sizes = get_available_sizes_for_filter(df)
size_filter = col3.selectbox("–†–∞–∑–º–µ—Ä (US)", ["–í—Å–µ"] + available_sizes)

# –ü–æ–ª
gender_filter = col4.selectbox("–ü–æ–ª", ["–í—Å–µ", "men", "women", "unisex"])

# –¶–≤–µ—Ç
color_filter = col5.selectbox("–¶–≤–µ—Ç", ["–í—Å–µ"] + sorted(df["color"].dropna().unique().tolist()))

# --- –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã ---
filtered_df = df.copy()
if brand_filter != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df["brand"] == brand_filter]
if model_filter != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df["model_clean"] == model_filter]
if size_filter != "–í—Å–µ":
    # –ü—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ (–≤–∫–ª—é—á–∞—è –¥—Ä–æ–±–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã)
    filtered_df = filtered_df[filtered_df["size US"] == size_filter]
if gender_filter != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df["gender"] == gender_filter]
if color_filter != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df["color"] == color_filter]

# –§–ò–õ–¨–¢–† –ü–û –ù–ê–õ–ò–ß–ò–Æ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–∞–∑–º–µ—Ä –≤ –Ω–∞–ª–∏—á–∏–∏
def has_any_size_in_stock(group):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–∞–∑–º–µ—Ä –≤ –Ω–∞–ª–∏—á–∏–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã —Ç–æ–≤–∞—Ä–æ–≤"""
    return any(
        str(row.get('in stock', 'yes')).strip().lower() == 'yes'
        for _, row in group.iterrows()
        if str(row['size US']).strip() and str(row['size US']).strip() != "nan"
    )

# –§–∏–ª—å—Ç—Ä—É–µ–º –≥—Ä—É–ø–ø—ã —Ç–æ–≤–∞—Ä–æ–≤, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–∞–∑–º–µ—Ä –≤ –Ω–∞–ª–∏—á–∏–∏
filtered_df = filtered_df.groupby(['brand', 'model_clean', 'color']).filter(has_any_size_in_stock)

st.divider()

# --- –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å–µ—Ç–∫–∞ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è Telegram ---
st.markdown("## –ö–∞—Ç–∞–ª–æ–≥ —Ç–æ–≤–∞—Ä–æ–≤")

if len(filtered_df) == 0:
    st.warning("–¢–æ–≤–∞—Ä—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
else:
    st.write(f"**–ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(filtered_df)}**")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–æ–¥–µ–ª–∏ –∏ —Ü–≤–µ—Ç—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    def get_first_with_image(group):
        """–ë–µ—Ä–µ—Ç –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–∑ –≥—Ä—É–ø–ø—ã"""
        for _, row in group.iterrows():
            if row['image'] and pd.notna(row['image']) and str(row['image']).strip():
                return row
        return group.iloc[0]

    grouped_df = filtered_df.groupby(['brand', 'model_clean', 'color']).apply(get_first_with_image).reset_index(drop=True)
    
    def get_available_sizes(group):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä—ã –≤ –Ω–∞–ª–∏—á–∏–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã"""
        available_sizes = []
        for _, row in group.iterrows():
            us_size = str(row['size US']).strip()
            in_stock = str(row.get('in stock', 'yes')).strip().lower()
            if us_size and us_size != "nan" and in_stock == 'yes':
                available_sizes.append(us_size)
        unique_sizes = list(dict.fromkeys(available_sizes))
        return ', '.join(sort_sizes(unique_sizes))
    
    size_groups = filtered_df.groupby(['brand', 'model_clean', 'color']).apply(get_available_sizes, include_groups=False).reset_index()
    size_groups.columns = ['brand', 'model_clean', 'color', 'size US']
    
    grouped_df = grouped_df.merge(size_groups, on=['brand', 'model_clean', 'color'], suffixes=('', '_grouped'))
    grouped_df['size US'] = grouped_df['size US_grouped']
    grouped_df = grouped_df.drop('size US_grouped', axis=1)
    grouped_df['size_eu'] = grouped_df['size US'].apply(get_eu_sizes)

    num_cols = 3
    rows = [grouped_df.iloc[i:i + num_cols] for i in range(0, len(grouped_df), num_cols)]

    for row_idx, row_df in enumerate(rows):
        cols = st.columns(num_cols)
        for col_idx, (col, (_, row)) in enumerate(zip(cols, row_df.iterrows())):
            with col:
                # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è Telegram
                image_names = row["image"]
                image_path = get_image_path(image_names)
                image_base64 = optimize_image_for_telegram(image_path)

                # –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞ —Ç–æ–≤–∞—Ä–∞
                st.markdown(
                    f"""
                    <div style="border: 1px solid #ddd; border-radius: 8px; padding: 8px; margin: 4px 0; background: white; height: 380px; display: flex; flex-direction: column;">
                        <img src="data:image/jpeg;base64,{image_base64}" style="width:100%; border-radius:6px; height:140px; object-fit:contain; background:#f8f9fa; margin-bottom:8px;">
                        <h4 style="margin:4px 0; font-size:13px; color:#333; line-height:1.2;">{row['brand']} {row['model_clean']}</h4>
                        <p style="color:#666; font-size:11px; margin:2px 0;">{row['color']} | {row['gender']}</p>
                        <div style="flex: 1; display: flex; gap: 8px; margin: 6px 0; align-items: center;">
                            <div style="flex: 1; font-size: 10px; text-align: center;">
                                <strong>US:</strong><br>{row['size US']}
                            </div>
                            <div style="flex: 1; font-size: 10px; text-align: center;">
                                <strong>EU:</strong><br>{row['size_eu']}
                            </div>
                        </div>
                        <p style="font-weight:bold; font-size:13px; margin:4px 0; color:#e74c3c;">{int(round(row['price'] / 1000) * 1000)} ‚Ç∏</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

                # –ö–Ω–æ–ø–∫–∞ "–ü–æ–¥—Ä–æ–±–Ω–µ–µ" - –í–ê–ñ–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç—Å—Ç—É–ø
                if st.button("–ü–æ–¥—Ä–æ–±–Ω–µ–µ", key=f"details_{row_idx}_{col_idx}", use_container_width=True):
                    st.session_state.product_data = dict(row)
                    st.switch_page("pages/2_–î–µ—Ç–∞–ª–∏_—Ç–æ–≤–∞—Ä–∞.py")

# --- –§–£–¢–ï–† ---
from components.documents import documents_footer
documents_footer()